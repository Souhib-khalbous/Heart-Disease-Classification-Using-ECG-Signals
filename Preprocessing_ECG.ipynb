{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Souhib-khalbous/Heart-Disease-Classification-Using-ECG-Signals/blob/master/Preprocessing_ECG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfLca_d3AOzc"
      },
      "outputs": [],
      "source": [
        "# Import the drive module from the google.colab library to enable Google Drive integration\n",
        "from google.colab import drive\n",
        "# Mount your Google Drive to the Colab VM to access files directly from your Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "l9GSYZNVAXRC",
        "outputId": "982edfd7-5975-4ba9-9b5f-bd080e01ec76"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "Unable to open file (file signature not found)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2614a3127ab6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Open the HDF5 file and directly access the 'f' dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Directly print the shape of the 'f' dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'f' dataset shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Open the HDF5 file and directly access the 'f' dataset\n",
        "with h5py.File(features_path, 'r') as file:\n",
        "    # Directly print the shape of the 'f' dataset\n",
        "    print(\"'f' dataset shape:\", file['f'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "9hZ527BOAzF-",
        "outputId": "7786d2bb-a414-4d40-c2ce-49345a28761e"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'f'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-72d511ce79c8>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Access the 'f' dataset and print its shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'f' dataset shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'f'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "mat_data = scipy.io.loadmat(features_path)\n",
        "\n",
        "# Check the contents of the .mat file\n",
        "print(mat_data.keys())\n",
        "\n",
        "# Access the 'f' dataset and print its shape\n",
        "f_data = mat_data['f']\n",
        "print(\"'f' dataset shape:\", f_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIP1qFw3CfJ-",
        "outputId": "4f518bcb-0004-4cf0-f2b0-c3a0a1b2ad47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size: 1196033254 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "import os\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Check if the file exists and its size\n",
        "if os.path.isfile(features_path):\n",
        "    file_size = os.path.getsize(features_path)\n",
        "    print(f\"File size: {file_size} bytes\")\n",
        "else:\n",
        "    print(\"File does not exist.\")\n",
        "\n",
        "# Try to load the .mat file\n",
        "try:\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "    print(\"Keys in the MAT file:\", mat_data.keys())\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J3SdLcpDPjH",
        "outputId": "5f7dbd31-3cc9-478b-c9f1-09b7b6923749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size: 1196033254 bytes\n",
            "Variables in the MAT file (first 10):\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "Name: , Shape: (0, 0), Type: double\n",
            "...and 320 more variables\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "import os\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Check if the file exists and its size\n",
        "if os.path.isfile(features_path):\n",
        "    file_size = os.path.getsize(features_path)\n",
        "    print(f\"File size: {file_size} bytes\")\n",
        "else:\n",
        "    print(\"File does not exist.\")\n",
        "\n",
        "# Try to load the .mat file and list the first few variable names\n",
        "try:\n",
        "    mat_data = scipy.io.whosmat(features_path)\n",
        "    print(\"Variables in the MAT file (first 10):\")\n",
        "    for var in mat_data[:10]:  # Limit the output to the first 10 variables\n",
        "        print(f\"Name: {var[0]}, Shape: {var[1]}, Type: {var[2]}\")\n",
        "    if len(mat_data) > 10:\n",
        "        print(f\"...and {len(mat_data) - 10} more variables\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeksNFpREKvR",
        "outputId": "75a53373-4037-4215-d94c-b2e76f506c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAT file loaded successfully.\n",
            "Error loading MAT file: 'features'\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "try:\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # Access the 'features' cell array\n",
        "    features = mat_data['features']\n",
        "\n",
        "    # Display the shape of the 'features' cell array\n",
        "    print(\"'features' cell array shape:\", features.shape)\n",
        "\n",
        "    # Iterate through the first few cells and display their content\n",
        "    for i in range(min(10, features.shape[0])):\n",
        "        cell_content = features[i, 0]\n",
        "        print(f\"Cell {i+1} content shape:\", cell_content.shape)\n",
        "        print(cell_content)\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4-DGllqEkA8",
        "outputId": "0ea45e85-747d-429b-fb2b-48972acebf22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all variables in the .mat file\n",
        "    print(\"Variables in the MAT file:\")\n",
        "    for key in mat_data.keys():\n",
        "        if not key.startswith('__'):\n",
        "            print(key)\n",
        "\n",
        "    # Assuming the variable of interest is named 'features'\n",
        "    # Replace 'features' with the actual variable name found\n",
        "    features = mat_data['features']  # Change this to the actual variable name\n",
        "    print(\"'features' variable shape:\", features.shape)\n",
        "\n",
        "    # Iterate through the first few cells and display their content\n",
        "    for i in range(min(10, features.shape[0])):\n",
        "        cell_content = features[i, 0]\n",
        "        print(f\"Cell {i+1} content shape:\", cell_content.shape)\n",
        "        print(cell_content)\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjYe87AaFW4n"
      },
      "outputs": [],
      "source": [
        "from notebook.services.config import ConfigManager\n",
        "cm = ConfigManager().update('notebook', {\n",
        "    'NotebookApp': {\n",
        "        'iopub_data_rate_limit': 10000000,  # Increase the limit to 10MB/sec\n",
        "        'rate_limit_window': 10.0  # Increase the window to 10 seconds\n",
        "    }\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJeAhv9SFZUh",
        "outputId": "a8b7b3dd-80d8-4fa6-af93-e5b26046f3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size: 1196033254 bytes\n",
            "MAT file loaded successfully.\n",
            "Total variables in the MAT file: 2\n",
            "Variable names have been written to /content/drive/MyDrive/Full Datasets (PTB and MIT)/variable_names.txt\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "import os\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "output_file_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/variable_names.txt'\n",
        "\n",
        "# Check if the file exists and its size\n",
        "if os.path.isfile(features_path):\n",
        "    file_size = os.path.getsize(features_path)\n",
        "    print(f\"File size: {file_size} bytes\")\n",
        "else:\n",
        "    print(\"File does not exist.\")\n",
        "\n",
        "# Try to load the .mat file and list the variable names\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all variables in the .mat file\n",
        "    variable_names = [key for key in mat_data.keys() if not key.startswith('__')]\n",
        "    print(f\"Total variables in the MAT file: {len(variable_names)}\")\n",
        "\n",
        "    # Write the variable names to a text file\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        file.write(\"Variables in the MAT file:\\n\")\n",
        "        for name in variable_names:\n",
        "            file.write(f\"{name}\\n\")\n",
        "\n",
        "    print(f\"Variable names have been written to {output_file_path}\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dStcpG8LE7m"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all top-level keys in the .mat file to inspect the structure\n",
        "    for key in mat_data.keys():\n",
        "        print(key)\n",
        "\n",
        "    # Assuming the data is stored in a structure at the first level\n",
        "    data_structure = mat_data[next(key for key in mat_data.keys() if not key.startswith('__'))]\n",
        "\n",
        "    # Print the shape and type of the data structure\n",
        "    print(\"Data structure shape:\", data_structure.shape)\n",
        "    print(\"Data structure type:\", type(data_structure))\n",
        "\n",
        "    # Assuming the first column contains features and the second column contains labels\n",
        "    feature_data = [data_structure[i, 0] for i in range(data_structure.shape[0])]\n",
        "    labels = [data_structure[i, 1] for i in range(data_structure.shape[0])]\n",
        "\n",
        "    # Convert to numpy arrays for easier manipulation\n",
        "    feature_data = np.array([f.flatten() for f in feature_data])  # Flatten each feature array\n",
        "    labels = np.array(labels).flatten()\n",
        "\n",
        "    print(\"Features shape:\", feature_data.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "    # Optionally, inspect the first few samples\n",
        "    print(\"First feature sample:\", feature_data[0])\n",
        "    print(\"First label:\", labels[0])\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzXKZABhB8fCtAZX2REWrV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}