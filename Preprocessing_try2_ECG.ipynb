{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJs9j1vDjH64nWEQx+sMdF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE-7vmqOLtWP",
        "outputId": "047244dd-27fd-445b-fd8c-7ad7d633ca2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import the drive module from the google.colab library to enable Google Drive integration\n",
        "from google.colab import drive\n",
        "# Mount your Google Drive to the Colab VM to access files directly from your Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all top-level keys in the .mat file to inspect the structure\n",
        "    for key in mat_data.keys():\n",
        "        print(key)\n",
        "\n",
        "    # Assuming the data is stored in a structure at the first level\n",
        "    data_structure = mat_data[next(key for key in mat_data.keys() if not key.startswith('__'))]\n",
        "\n",
        "    # Print the shape and type of the data structure\n",
        "    print(\"Data structure shape:\", data_structure.shape)\n",
        "    print(\"Data structure type:\", type(data_structure))\n",
        "\n",
        "    # Assuming the first column contains features and the second column contains labels\n",
        "    feature_data = [data_structure[i, 0] for i in range(data_structure.shape[0])]\n",
        "    labels = [data_structure[i, 1] for i in range(data_structure.shape[0])]\n",
        "\n",
        "    # Convert to numpy arrays for easier manipulation\n",
        "    feature_data = np.array([f.flatten() for f in feature_data])  # Flatten each feature array\n",
        "    labels = np.array(labels).flatten()\n",
        "\n",
        "    print(\"Features shape:\", feature_data.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "    # Optionally, inspect the first few samples\n",
        "    print(\"First feature sample:\", feature_data[0])\n",
        "    print(\"First label:\", labels[0])\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGgZEvu0L25w",
        "outputId": "7c9afe03-620e-46cb-f477-3fa216299f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This step is usually not necessary in Colab, but if needed, you can use:\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n"
      ],
      "metadata": {
        "id": "0Q4ThY8TNNsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "output_file_path = '/content/output.txt'\n",
        "\n",
        "# Load the .mat file and separate features and labels\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # Extract the first key (ignoring meta keys starting with '__')\n",
        "    data_structure_key = next(key for key in mat_data.keys() if not key.startswith('__'))\n",
        "    data_structure = mat_data[data_structure_key]\n",
        "\n",
        "    # Print the shape and type of the data structure\n",
        "    print(\"Data structure shape:\", data_structure.shape)\n",
        "    print(\"Data structure type:\", type(data_structure))\n",
        "\n",
        "    # Initialize lists to store features and labels\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over the rows of the data structure\n",
        "    for i in range(data_structure.shape[0]):\n",
        "        feature_array = data_structure[i, 0]  # Access the feature array\n",
        "        label = data_structure[i, 1]  # Access the label\n",
        "\n",
        "        # Flatten the feature array and extract the label\n",
        "        features.append(feature_array.flatten())\n",
        "        labels.append(label[0][0])  # Convert label to a scalar value\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        f.write(\"Features and labels extracted successfully.\\n\")\n",
        "        f.write(f\"Features shape: {features.shape}\\n\")\n",
        "        f.write(f\"Labels shape: {labels.shape}\\n\")\n",
        "        f.write(f\"First feature sample shape: {features[0].shape}\\n\")\n",
        "        f.write(f\"First label: {labels[0]}\\n\")\n",
        "\n",
        "    print(f\"Features and labels data written to {output_file_path}\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ5HyXcUNQSA",
        "outputId": "51921f32-e945-4e0e-9101-1d53652bff9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAT file loaded successfully.\n",
            "Data structure shape: (0, 0)\n",
            "Data structure type: <class 'numpy.ndarray'>\n",
            "Error loading MAT file: index 0 is out of bounds for axis 0 with size 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the contents of the output file\n",
        "with open(output_file_path, 'r') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HhQ4ntGP8Xo",
        "outputId": "0823136e-ad42-43a1-e43c-1d12e9ca4132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "try:\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all top-level keys in the .mat file to inspect the structure\n",
        "    for key in mat_data.keys():\n",
        "        if not key.startswith('__'):\n",
        "            print(f\"Key: {key}, Shape: {mat_data[key].shape}, Type: {type(mat_data[key])}\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHuXnK6BR3JI",
        "outputId": "e290f9e4-7cd0-4626-854f-cca6df04cbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAT file loaded successfully.\n",
            "Key: , Shape: (0, 0), Type: <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "output_file_path = '/content/output.txt'\n",
        "\n",
        "# Load the .mat file and separate features and labels\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # Inspect the top-level keys to identify the structure\n",
        "    for key in mat_data.keys():\n",
        "        if not key.startswith('__'):\n",
        "            print(f\"Key: {key}, Shape: {mat_data[key].shape}, Type: {type(mat_data[key])}\")\n",
        "\n",
        "    # Assuming the main data structure is stored under a certain key (update this based on Step 1 output)\n",
        "    key = next(key for key in mat_data.keys() if not key.startswith('__'))\n",
        "    data_structure = mat_data[key]\n",
        "\n",
        "    # Initialize lists to store features and labels\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over the rows of the data structure\n",
        "    for i in range(data_structure.shape[0]):\n",
        "        feature_array = data_structure[i, 0]\n",
        "        label = data_structure[i, 1]  # Access the label\n",
        "\n",
        "        # Flatten the feature array and extract the label\n",
        "        features.append(feature_array.flatten())\n",
        "        labels.append(label[0][0])  # Convert label to a scalar value\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        f.write(\"Features and labels extracted successfully.\\n\")\n",
        "        f.write(f\"Features shape: {features.shape}\\n\")\n",
        "        f.write(f\"Labels shape: {labels.shape}\\n\")\n",
        "        f.write(f\"First feature sample shape: {features[0].shape}\\n\")\n",
        "        f.write(f\"First label: {labels[0]}\\n\")\n",
        "\n",
        "    print(f\"Features and labels data written to {output_file_path}\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3yItc1lR5Hs",
        "outputId": "2f036002-02a6-4ce9-efd1-d09f8dea44fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "\n",
        "# Load the .mat file\n",
        "try:\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all top-level keys in the .mat file to inspect the structure\n",
        "    keys = [key for key in mat_data.keys() if not key.startswith('__')]\n",
        "    print(f\"Keys in the MAT file: {keys}\")\n",
        "\n",
        "    # Inspect the first few entries of each key to understand the structure\n",
        "    for key in keys:\n",
        "        print(f\"\\nInspecting key: {key}\")\n",
        "        data = mat_data[key]\n",
        "        print(f\"Shape: {data.shape}, Type: {type(data)}\")\n",
        "\n",
        "        # Inspect the first few entries to avoid overwhelming the output\n",
        "        if isinstance(data, np.ndarray) and data.size > 0:\n",
        "            if data.ndim == 2:\n",
        "                for i in range(min(5, data.shape[0])):\n",
        "                    for j in range(min(2, data.shape[1])):\n",
        "                        print(f\"Entry [{i}, {j}]: Type: {type(data[i, j])}, Content: {data[i, j]}\")\n",
        "            else:\n",
        "                print(f\"Content: {data}\")\n",
        "        else:\n",
        "            print(\"Data is empty or not an ndarray.\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr08dqxZTvWW",
        "outputId": "b3a8792e-ea58-46ee-e4b0-2353bec0b6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "# Specify the path to the dataset\n",
        "features_path = '/content/drive/MyDrive/Full Datasets (PTB and MIT)/featuresHavva.mat'\n",
        "output_file_path = '/content/drive/MyDrive/inspection_output.txt'\n",
        "\n",
        "# Load the .mat file and inspect its structure\n",
        "try:\n",
        "    # Load the .mat file\n",
        "    mat_data = scipy.io.loadmat(features_path)\n",
        "    print(\"MAT file loaded successfully.\")\n",
        "\n",
        "    # List all top-level keys and their details\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        keys = [key for key in mat_data.keys() if not key.startswith('__')]\n",
        "        f.write(f\"Keys in the MAT file: {keys}\\n\")\n",
        "\n",
        "        for key in keys:\n",
        "            f.write(f\"\\nInspecting key: {key}\\n\")\n",
        "            data = mat_data[key]\n",
        "            f.write(f\"Shape: {data.shape}, Type: {type(data)}\\n\")\n",
        "\n",
        "            # Inspect the first few entries to avoid overwhelming the output\n",
        "            if isinstance(data, np.ndarray) and data.size > 0:\n",
        "                if data.ndim == 2:\n",
        "                    for i in range(min(5, data.shape[0])):\n",
        "                        for j in range(min(2, data.shape[1])):\n",
        "                            entry = data[i, j]\n",
        "                            entry_type = type(entry)\n",
        "                            entry_content = str(entry)[:100]  # Limit content length for readability\n",
        "                            f.write(f\"Entry [{i}, {j}]: Type: {entry_type}, Content: {entry_content}\\n\")\n",
        "                elif data.ndim == 1:\n",
        "                    for i in range(min(5, data.shape[0])):\n",
        "                        entry = data[i]\n",
        "                        entry_type = type(entry)\n",
        "                        entry_content = str(entry)[:100]  # Limit content length for readability\n",
        "                        f.write(f\"Entry [{i}]: Type: {entry_type}, Content: {entry_content}\\n\")\n",
        "                else:\n",
        "                    f.write(f\"Content: {str(data)[:500]}\\n\")  # Limit content length for readability\n",
        "            else:\n",
        "                f.write(\"Data is empty or not an ndarray.\\n\")\n",
        "\n",
        "    print(f\"Inspection data written to {output_file_path}\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading MAT file:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdVaBoJnU2pm",
        "outputId": "9ed9a742-8456-426b-86b9-79a4f620a3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAT file loaded successfully.\n",
            "Inspection data written to /content/inspection_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the correct path to the inspection output file\n",
        "output_file_path = '/content/output.txt'\n",
        "\n",
        "# Read the contents of the inspection output file and display it\n",
        "try:\n",
        "    with open(output_file_path, 'r') as f:\n",
        "        inspection_output = f.read()\n",
        "    print(inspection_output)\n",
        "except Exception as e:\n",
        "    print(f\"Error reading the inspection output file: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0arC3uxkWg12",
        "outputId": "7bc38648-b5a2-4526-c703-da17b67f468b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and labels extracted successfully.\n",
            "Features shape: (0,)\n",
            "Labels shape: (0,)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}